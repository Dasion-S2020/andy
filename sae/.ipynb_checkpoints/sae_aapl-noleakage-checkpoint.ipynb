{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we import the necessary libraries.\n",
    "#pywt is a wavelet transformation library which I found is easier to apply than manually coding functions up.\n",
    "from __future__ import print_function\n",
    "import pywt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>bb_bbm</th>\n",
       "      <th>bb_bbh</th>\n",
       "      <th>bb_bbl</th>\n",
       "      <th>atr</th>\n",
       "      <th>macd</th>\n",
       "      <th>cci</th>\n",
       "      <th>ema</th>\n",
       "      <th>sma12</th>\n",
       "      <th>sma5</th>\n",
       "      <th>stochastic_oscillator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/8/00</td>\n",
       "      <td>4.0714</td>\n",
       "      <td>4.1027</td>\n",
       "      <td>3.9755</td>\n",
       "      <td>4.1451</td>\n",
       "      <td>0</td>\n",
       "      <td>3.742555</td>\n",
       "      <td>4.258224</td>\n",
       "      <td>3.226886</td>\n",
       "      <td>0.258809</td>\n",
       "      <td>0.028209</td>\n",
       "      <td>108.782044</td>\n",
       "      <td>3.824942</td>\n",
       "      <td>3.819608</td>\n",
       "      <td>3.85050</td>\n",
       "      <td>75.940406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/9/00</td>\n",
       "      <td>4.0804</td>\n",
       "      <td>4.0224</td>\n",
       "      <td>4.0179</td>\n",
       "      <td>4.1786</td>\n",
       "      <td>0</td>\n",
       "      <td>3.778050</td>\n",
       "      <td>4.267487</td>\n",
       "      <td>3.288613</td>\n",
       "      <td>0.251801</td>\n",
       "      <td>0.041007</td>\n",
       "      <td>99.551288</td>\n",
       "      <td>3.851270</td>\n",
       "      <td>3.838583</td>\n",
       "      <td>3.94916</td>\n",
       "      <td>80.342311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/10/00</td>\n",
       "      <td>4.0224</td>\n",
       "      <td>4.0536</td>\n",
       "      <td>3.9130</td>\n",
       "      <td>4.0670</td>\n",
       "      <td>0</td>\n",
       "      <td>3.825040</td>\n",
       "      <td>4.222099</td>\n",
       "      <td>3.427981</td>\n",
       "      <td>0.244815</td>\n",
       "      <td>0.053055</td>\n",
       "      <td>72.677158</td>\n",
       "      <td>3.878247</td>\n",
       "      <td>3.842308</td>\n",
       "      <td>4.02192</td>\n",
       "      <td>84.268815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/11/00</td>\n",
       "      <td>4.0581</td>\n",
       "      <td>3.8840</td>\n",
       "      <td>3.8706</td>\n",
       "      <td>4.0759</td>\n",
       "      <td>0</td>\n",
       "      <td>3.846470</td>\n",
       "      <td>4.205897</td>\n",
       "      <td>3.487043</td>\n",
       "      <td>0.241993</td>\n",
       "      <td>0.048361</td>\n",
       "      <td>40.605138</td>\n",
       "      <td>3.879014</td>\n",
       "      <td>3.838033</td>\n",
       "      <td>4.02728</td>\n",
       "      <td>62.924742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/14/00</td>\n",
       "      <td>3.9018</td>\n",
       "      <td>4.1362</td>\n",
       "      <td>3.8840</td>\n",
       "      <td>4.1384</td>\n",
       "      <td>0</td>\n",
       "      <td>3.873925</td>\n",
       "      <td>4.233795</td>\n",
       "      <td>3.514055</td>\n",
       "      <td>0.242879</td>\n",
       "      <td>0.064250</td>\n",
       "      <td>80.649750</td>\n",
       "      <td>3.913306</td>\n",
       "      <td>3.855333</td>\n",
       "      <td>4.03978</td>\n",
       "      <td>94.663982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date    open   close     low    high  volume    bb_bbm    bb_bbh  \\\n",
       "0   2/8/00  4.0714  4.1027  3.9755  4.1451       0  3.742555  4.258224   \n",
       "1   2/9/00  4.0804  4.0224  4.0179  4.1786       0  3.778050  4.267487   \n",
       "2  2/10/00  4.0224  4.0536  3.9130  4.0670       0  3.825040  4.222099   \n",
       "3  2/11/00  4.0581  3.8840  3.8706  4.0759       0  3.846470  4.205897   \n",
       "4  2/14/00  3.9018  4.1362  3.8840  4.1384       0  3.873925  4.233795   \n",
       "\n",
       "     bb_bbl       atr      macd         cci       ema     sma12     sma5  \\\n",
       "0  3.226886  0.258809  0.028209  108.782044  3.824942  3.819608  3.85050   \n",
       "1  3.288613  0.251801  0.041007   99.551288  3.851270  3.838583  3.94916   \n",
       "2  3.427981  0.244815  0.053055   72.677158  3.878247  3.842308  4.02192   \n",
       "3  3.487043  0.241993  0.048361   40.605138  3.879014  3.838033  4.02728   \n",
       "4  3.514055  0.242879  0.064250   80.649750  3.913306  3.855333  4.03978   \n",
       "\n",
       "   stochastic_oscillator  \n",
       "0              75.940406  \n",
       "1              80.342311  \n",
       "2              84.268815  \n",
       "3              62.924742  \n",
       "4              94.663982  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('/Users/andyliu/develop/andy/aapl_indicators_nosplit.csv')\n",
    "df2 = df1.iloc[:,1:]\n",
    "df3 = df2.drop(labels=['roc', 'mtm6', 'mtm12'], axis=1)\n",
    "df1 = df3\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[list(df1.columns)] = df1[list(df1.columns)].apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1[['open', 'high', 'low', 'close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df3.close.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df3.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'close', 'low', 'high', 'volume', 'bb_bbm', 'bb_bbh', 'bb_bbl',\n",
       "       'atr', 'macd', 'cci', 'ema', 'sma12', 'sma5', 'stochastic_oscillator'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.drop(['date'], axis=1)\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2=df2.drop(df2.index[-1])\n",
    "#df1[['open','high','low','close']]=df2[['open','high','low','close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.interpolate(method='akima')\n",
    "df1.replace(np.inf, np.nan)\n",
    "df1=df1.dropna(subset=['open', 'high', 'low', 'close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'close', 'low', 'high', 'volume', 'bb_bbm', 'bb_bbh', 'bb_bbl',\n",
       "       'atr', 'macd', 'cci', 'ema', 'sma12', 'sma5', 'stochastic_oscillator'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df1 = df1.drop(['date'], axis=1)\n",
    "close = df1['close']\n",
    "#df1 = df1.drop(['close'], axis=1)\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2545 4581 5090\n"
     ]
    }
   ],
   "source": [
    "g = df1.values\n",
    "r = g.shape[0]\n",
    "n_train = r//2\n",
    "n1_train = 9*r//10\n",
    "print(n_train, n1_train, r)\n",
    "#train_indices = random.sample(range(r), n_train)\n",
    "#test_indices = [i for i in list(range(r)) if i not in train_indices]\n",
    "#train_indices.sort()\n",
    "#test_indices.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2036, 15)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_cols = ['open', 'high', 'low', 'close']\n",
    "price_data = df1[price_cols]\n",
    "#data = df1.drop('close', axis=1)\n",
    "#data = df1.drop('date', axis=1)\n",
    "#exp_X_train=g[train_indices,:]\n",
    "#exp_X_test=g[test_indices,:]\n",
    "exp_X_train = g[n_train:n1_train,:]\n",
    "exp_X_test = g[n1_train:,:]\n",
    "#h = price.values\n",
    "exp_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_train = price_data[n_train:n1_train]\n",
    "price_test = price_data[n1_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>34.2329</td>\n",
       "      <td>34.5500</td>\n",
       "      <td>34.1086</td>\n",
       "      <td>34.3457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>34.2014</td>\n",
       "      <td>34.4586</td>\n",
       "      <td>34.0257</td>\n",
       "      <td>34.2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>34.4143</td>\n",
       "      <td>34.6586</td>\n",
       "      <td>34.3614</td>\n",
       "      <td>34.5857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>34.6514</td>\n",
       "      <td>34.7243</td>\n",
       "      <td>34.5500</td>\n",
       "      <td>34.6386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>34.5429</td>\n",
       "      <td>34.7557</td>\n",
       "      <td>34.4286</td>\n",
       "      <td>34.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>34.8514</td>\n",
       "      <td>35.1757</td>\n",
       "      <td>34.7429</td>\n",
       "      <td>35.1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>34.9800</td>\n",
       "      <td>35.5700</td>\n",
       "      <td>34.9571</td>\n",
       "      <td>35.4143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>35.4557</td>\n",
       "      <td>35.8557</td>\n",
       "      <td>34.9743</td>\n",
       "      <td>35.3414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>35.2271</td>\n",
       "      <td>35.4014</td>\n",
       "      <td>34.5691</td>\n",
       "      <td>35.1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>35.5286</td>\n",
       "      <td>37.7657</td>\n",
       "      <td>34.7214</td>\n",
       "      <td>35.0629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>36.7300</td>\n",
       "      <td>37.2429</td>\n",
       "      <td>36.5714</td>\n",
       "      <td>36.9429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>37.0757</td>\n",
       "      <td>38.0957</td>\n",
       "      <td>36.6329</td>\n",
       "      <td>38.0286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>38.1057</td>\n",
       "      <td>38.8571</td>\n",
       "      <td>38.0486</td>\n",
       "      <td>38.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>38.8571</td>\n",
       "      <td>38.9714</td>\n",
       "      <td>38.3150</td>\n",
       "      <td>38.4514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>38.3229</td>\n",
       "      <td>38.3229</td>\n",
       "      <td>37.2857</td>\n",
       "      <td>37.4371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>36.7443</td>\n",
       "      <td>37.7686</td>\n",
       "      <td>36.4457</td>\n",
       "      <td>37.2143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>37.4714</td>\n",
       "      <td>38.5643</td>\n",
       "      <td>37.4029</td>\n",
       "      <td>38.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>38.5000</td>\n",
       "      <td>38.6543</td>\n",
       "      <td>37.2871</td>\n",
       "      <td>37.3457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>37.4814</td>\n",
       "      <td>38.2557</td>\n",
       "      <td>37.2986</td>\n",
       "      <td>37.9643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>38.0071</td>\n",
       "      <td>38.0071</td>\n",
       "      <td>36.7214</td>\n",
       "      <td>36.8686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>36.6714</td>\n",
       "      <td>36.8756</td>\n",
       "      <td>35.6357</td>\n",
       "      <td>36.5786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>36.4514</td>\n",
       "      <td>37.1429</td>\n",
       "      <td>30.0957</td>\n",
       "      <td>34.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>34.6857</td>\n",
       "      <td>35.3886</td>\n",
       "      <td>32.2071</td>\n",
       "      <td>33.6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>36.4286</td>\n",
       "      <td>36.5714</td>\n",
       "      <td>35.2500</td>\n",
       "      <td>36.3086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>36.2143</td>\n",
       "      <td>37.1140</td>\n",
       "      <td>35.7171</td>\n",
       "      <td>36.4657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>36.6457</td>\n",
       "      <td>37.5643</td>\n",
       "      <td>36.6071</td>\n",
       "      <td>37.4571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>37.2943</td>\n",
       "      <td>37.8494</td>\n",
       "      <td>36.6643</td>\n",
       "      <td>37.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>36.7429</td>\n",
       "      <td>36.7429</td>\n",
       "      <td>35.7171</td>\n",
       "      <td>35.9929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>36.1414</td>\n",
       "      <td>36.5743</td>\n",
       "      <td>35.4329</td>\n",
       "      <td>36.3271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>36.5171</td>\n",
       "      <td>36.9157</td>\n",
       "      <td>35.6714</td>\n",
       "      <td>35.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>165.5000</td>\n",
       "      <td>166.3000</td>\n",
       "      <td>161.4100</td>\n",
       "      <td>163.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4552</th>\n",
       "      <td>163.1000</td>\n",
       "      <td>165.3900</td>\n",
       "      <td>161.9000</td>\n",
       "      <td>164.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>164.5000</td>\n",
       "      <td>165.6600</td>\n",
       "      <td>163.4100</td>\n",
       "      <td>164.8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4554</th>\n",
       "      <td>164.8000</td>\n",
       "      <td>165.1599</td>\n",
       "      <td>160.7099</td>\n",
       "      <td>162.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4555</th>\n",
       "      <td>162.7000</td>\n",
       "      <td>167.1730</td>\n",
       "      <td>161.9200</td>\n",
       "      <td>166.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4556</th>\n",
       "      <td>166.2000</td>\n",
       "      <td>177.5200</td>\n",
       "      <td>165.5300</td>\n",
       "      <td>175.2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4557</th>\n",
       "      <td>174.7000</td>\n",
       "      <td>177.6960</td>\n",
       "      <td>173.7100</td>\n",
       "      <td>176.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4558</th>\n",
       "      <td>176.2500</td>\n",
       "      <td>177.4334</td>\n",
       "      <td>174.4900</td>\n",
       "      <td>177.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>177.5000</td>\n",
       "      <td>188.0581</td>\n",
       "      <td>177.4700</td>\n",
       "      <td>188.0581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>184.4500</td>\n",
       "      <td>187.6200</td>\n",
       "      <td>184.2500</td>\n",
       "      <td>184.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>185.1600</td>\n",
       "      <td>186.1900</td>\n",
       "      <td>183.7700</td>\n",
       "      <td>186.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>186.4000</td>\n",
       "      <td>187.5000</td>\n",
       "      <td>185.2700</td>\n",
       "      <td>187.4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>187.4400</td>\n",
       "      <td>190.2600</td>\n",
       "      <td>187.2000</td>\n",
       "      <td>189.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>189.6000</td>\n",
       "      <td>190.0274</td>\n",
       "      <td>187.5400</td>\n",
       "      <td>188.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>189.0200</td>\n",
       "      <td>189.5100</td>\n",
       "      <td>187.8200</td>\n",
       "      <td>187.8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4566</th>\n",
       "      <td>187.4400</td>\n",
       "      <td>187.6800</td>\n",
       "      <td>185.1410</td>\n",
       "      <td>185.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4567</th>\n",
       "      <td>186.1600</td>\n",
       "      <td>188.3900</td>\n",
       "      <td>185.5000</td>\n",
       "      <td>188.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4568</th>\n",
       "      <td>187.7500</td>\n",
       "      <td>188.8800</td>\n",
       "      <td>186.3900</td>\n",
       "      <td>186.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>187.1900</td>\n",
       "      <td>187.7500</td>\n",
       "      <td>186.2000</td>\n",
       "      <td>186.4100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>187.2100</td>\n",
       "      <td>189.2400</td>\n",
       "      <td>186.9500</td>\n",
       "      <td>187.5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>187.9200</td>\n",
       "      <td>188.7400</td>\n",
       "      <td>186.8200</td>\n",
       "      <td>187.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>185.9900</td>\n",
       "      <td>188.8100</td>\n",
       "      <td>184.6500</td>\n",
       "      <td>188.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>188.7000</td>\n",
       "      <td>189.0000</td>\n",
       "      <td>186.3600</td>\n",
       "      <td>188.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>188.7800</td>\n",
       "      <td>189.6500</td>\n",
       "      <td>187.7092</td>\n",
       "      <td>188.7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4575</th>\n",
       "      <td>187.9400</td>\n",
       "      <td>188.6300</td>\n",
       "      <td>186.7000</td>\n",
       "      <td>187.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>188.5000</td>\n",
       "      <td>188.6200</td>\n",
       "      <td>186.8100</td>\n",
       "      <td>187.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4577</th>\n",
       "      <td>187.9000</td>\n",
       "      <td>188.1610</td>\n",
       "      <td>186.2800</td>\n",
       "      <td>186.9700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>187.5300</td>\n",
       "      <td>190.5000</td>\n",
       "      <td>187.4000</td>\n",
       "      <td>190.4900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579</th>\n",
       "      <td>191.0000</td>\n",
       "      <td>193.3500</td>\n",
       "      <td>190.8000</td>\n",
       "      <td>192.3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>192.2100</td>\n",
       "      <td>193.9200</td>\n",
       "      <td>192.2100</td>\n",
       "      <td>193.3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2036 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open      high       low     close\n",
       "2545   34.2329   34.5500   34.1086   34.3457\n",
       "2546   34.2014   34.4586   34.0257   34.2957\n",
       "2547   34.4143   34.6586   34.3614   34.5857\n",
       "2548   34.6514   34.7243   34.5500   34.6386\n",
       "2549   34.5429   34.7557   34.4286   34.7500\n",
       "2550   34.8514   35.1757   34.7429   35.1286\n",
       "2551   34.9800   35.5700   34.9571   35.4143\n",
       "2552   35.4557   35.8557   34.9743   35.3414\n",
       "2553   35.2271   35.4014   34.5691   35.1143\n",
       "2554   35.5286   37.7657   34.7214   35.0629\n",
       "2555   36.7300   37.2429   36.5714   36.9429\n",
       "2556   37.0757   38.0957   36.6329   38.0286\n",
       "2557   38.1057   38.8571   38.0486   38.7100\n",
       "2558   38.8571   38.9714   38.3150   38.4514\n",
       "2559   38.3229   38.3229   37.2857   37.4371\n",
       "2560   36.7443   37.7686   36.4457   37.2143\n",
       "2561   37.4714   38.5643   37.4029   38.3000\n",
       "2562   38.5000   38.6543   37.2871   37.3457\n",
       "2563   37.4814   38.2557   37.2986   37.9643\n",
       "2564   38.0071   38.0071   36.7214   36.8686\n",
       "2565   36.6714   36.8756   35.6357   36.5786\n",
       "2566   36.4514   37.1429   30.0957   34.5714\n",
       "2567   34.6857   35.3886   32.2071   33.6100\n",
       "2568   36.4286   36.5714   35.2500   36.3086\n",
       "2569   36.2143   37.1140   35.7171   36.4657\n",
       "2570   36.6457   37.5643   36.6071   37.4571\n",
       "2571   37.2943   37.8494   36.6643   37.0000\n",
       "2572   36.7429   36.7429   35.7171   35.9929\n",
       "2573   36.1414   36.5743   35.4329   36.3271\n",
       "2574   36.5171   36.9157   35.6714   35.7143\n",
       "...        ...       ...       ...       ...\n",
       "4551  165.5000  166.3000  161.4100  163.0800\n",
       "4552  163.1000  165.3900  161.9000  164.9900\n",
       "4553  164.5000  165.6600  163.4100  164.8300\n",
       "4554  164.8000  165.1599  160.7099  162.1700\n",
       "4555  162.7000  167.1730  161.9200  166.1500\n",
       "4556  166.2000  177.5200  165.5300  175.2900\n",
       "4557  174.7000  177.6960  173.7100  176.5000\n",
       "4558  176.2500  177.4334  174.4900  177.0000\n",
       "4559  177.5000  188.0581  177.4700  188.0581\n",
       "4560  184.4500  187.6200  184.2500  184.9500\n",
       "4561  185.1600  186.1900  183.7700  186.0000\n",
       "4562  186.4000  187.5000  185.2700  187.4800\n",
       "4563  187.4400  190.2600  187.2000  189.8500\n",
       "4564  189.6000  190.0274  187.5400  188.5500\n",
       "4565  189.0200  189.5100  187.8200  187.8200\n",
       "4566  187.4400  187.6800  185.1410  185.8000\n",
       "4567  186.1600  188.3900  185.5000  188.1500\n",
       "4568  187.7500  188.8800  186.3900  186.9500\n",
       "4569  187.1900  187.7500  186.2000  186.4100\n",
       "4570  187.2100  189.2400  186.9500  187.5900\n",
       "4571  187.9200  188.7400  186.8200  187.2500\n",
       "4572  185.9900  188.8100  184.6500  188.6500\n",
       "4573  188.7000  189.0000  186.3600  188.5000\n",
       "4574  188.7800  189.6500  187.7092  188.7300\n",
       "4575  187.9400  188.6300  186.7000  187.7000\n",
       "4576  188.5000  188.6200  186.8100  187.1700\n",
       "4577  187.9000  188.1610  186.2800  186.9700\n",
       "4578  187.5300  190.5000  187.4000  190.4900\n",
       "4579  191.0000  193.3500  190.8000  192.3500\n",
       "4580  192.2100  193.9200  192.2100  193.3000\n",
       "\n",
       "[2036 rows x 4 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2036, 15) (509, 15)\n"
     ]
    }
   ],
   "source": [
    "#exp_y_train=h[train_indices]\n",
    "#exp_y_test=h[test_indices]\n",
    "print(exp_X_train.shape, exp_X_test.shape)\n",
    "#print(price_train.shape, price_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs= pywt.wavedec2(price_train, 'haar',  mode='symmetric',level=2)\n",
    "coeffs[-1] = tuple([np.zeros_like(v) for v in coeffs[-1]])\n",
    "c=pywt.waverec2(coeffs,'haar')\n",
    "coeffs1=pywt.wavedec2(c,'haar', mode='symmetric', level=2)\n",
    "coeffs1[-1] = tuple([np.zeros_like(v) for v in coeffs1[-1]])\n",
    "d=pywt.waverec2(coeffs1, 'haar')\n",
    "exp_X_train[:,0] = d[:,0]\n",
    "exp_X_train[:,1] = d[:,1]\n",
    "exp_X_train[:,2] = d[:,2]\n",
    "exp_X_train[:,3] = d[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 34.360725,  34.360725,  34.61215 , ..., 188.52275 , 192.62    ,\n",
       "       192.62    ])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_X_train[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307548</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.681400</td>\n",
       "      <td>0.730498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.307647</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.681347</td>\n",
       "      <td>0.693755</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.917817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.307684</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.681654</td>\n",
       "      <td>0.700272</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.977239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.307723</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.681671</td>\n",
       "      <td>0.689866</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.968293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.308245</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.681601</td>\n",
       "      <td>0.676055</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.997625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3    4         5         6         7   \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.307548   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.0  0.000713  0.000814  0.307647   \n",
       "2  0.001589  0.001589  0.002152  0.002152  0.0  0.001487  0.001760  0.307684   \n",
       "3  0.001589  0.001589  0.002152  0.002152  0.0  0.002206  0.002637  0.307723   \n",
       "4  0.002974  0.002974  0.003599  0.003599  0.0  0.003141  0.003348  0.308245   \n",
       "\n",
       "         8         9         10        11        12        13        14  \n",
       "0  0.000706  0.681400  0.730498  0.000000  0.000000  0.000000  0.933975  \n",
       "1  0.000589  0.681347  0.693755  0.000930  0.001175  0.000870  0.917817  \n",
       "2  0.000444  0.681654  0.700272  0.001984  0.002242  0.001987  0.977239  \n",
       "3  0.000208  0.681671  0.689866  0.002944  0.003243  0.002651  0.968293  \n",
       "4  0.000071  0.681601  0.676055  0.003871  0.004488  0.003314  0.997625  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler= preprocessing.MinMaxScaler()\n",
    "scaler.fit(exp_X_train)\n",
    "exp_X_train=scaler.transform(exp_X_train)\n",
    "scaled_df1=pd.DataFrame(exp_X_train)\n",
    "scaled_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2036"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_train = d[:,1]\n",
    "len(price_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the keras library to start constructing the LSTM network\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred-y_true),axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2036, 14)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_train = exp_X_train[:,1]\n",
    "exp_X_train = np.delete(exp_X_train, 1, axis=1)\n",
    "exp_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2036, 1, 14) (2036,)\n"
     ]
    }
   ],
   "source": [
    "X_train= exp_X_train.reshape((exp_X_train.shape[0],1,exp_X_train.shape[1]))\n",
    "#X_test=exp_X_test.reshape((exp_X_test.shape[0],1,exp_X_test.shape[1]))\n",
    "y_train=price_train\n",
    "#y_test=exp_y_test\n",
    "#print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.00158869, ..., 0.97411052, 1.        ,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 1, 60)             18000     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1, 60)             0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 1, 120)            86880     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1, 120)            0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 1, 240)            346560    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 240)            0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 60)                72240     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 61        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 523,741\n",
      "Trainable params: 523,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "neurons=60\n",
    "dropout=0.20\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(neurons, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]), activation='sigmoid'))\n",
    "model1.add(Dropout(dropout))\n",
    "model1.add(LSTM(neurons*2, return_sequences=True, activation='sigmoid'))\n",
    "model1.add(Dropout(dropout))\n",
    "model1.add(LSTM(neurons*4, return_sequences=True, activation='sigmoid'))\n",
    "model1.add(Dropout(dropout))\n",
    "model1.add(LSTM(neurons, activation='sigmoid'))\n",
    "model1.add(Dense(units=1))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.compile(loss='mse', optimizer='adam')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "2036/2036 [==============================] - 0s 236us/step - loss: 0.4445\n",
      "Epoch 2/5000\n",
      "2036/2036 [==============================] - 0s 227us/step - loss: 0.4445\n",
      "Epoch 3/5000\n",
      "2036/2036 [==============================] - 0s 236us/step - loss: 0.4445\n",
      "Epoch 4/5000\n",
      "2036/2036 [==============================] - 1s 253us/step - loss: 0.4445\n",
      "Epoch 5/5000\n",
      "2036/2036 [==============================] - 1s 336us/step - loss: 0.4445\n",
      "Epoch 6/5000\n",
      "2036/2036 [==============================] - 0s 231us/step - loss: 0.4445\n",
      "Epoch 7/5000\n",
      "2036/2036 [==============================] - 0s 238us/step - loss: 0.4445\n",
      "Epoch 8/5000\n",
      "2036/2036 [==============================] - 0s 232us/step - loss: 0.4445\n",
      "Epoch 9/5000\n",
      "2036/2036 [==============================] - 0s 240us/step - loss: 0.4445\n",
      "Epoch 10/5000\n",
      "2036/2036 [==============================] - 1s 251us/step - loss: 0.4445\n",
      "Epoch 11/5000\n",
      "2036/2036 [==============================] - 0s 229us/step - loss: 0.4445\n",
      "Epoch 12/5000\n",
      "2036/2036 [==============================] - 0s 229us/step - loss: 0.4445\n",
      "Epoch 13/5000\n",
      "2036/2036 [==============================] - 0s 236us/step - loss: 0.4445\n",
      "Epoch 14/5000\n",
      "2036/2036 [==============================] - 0s 222us/step - loss: 0.4445\n",
      "Epoch 15/5000\n",
      "2036/2036 [==============================] - 1s 303us/step - loss: 0.4445\n",
      "Epoch 16/5000\n",
      "2036/2036 [==============================] - 1s 252us/step - loss: 0.4445\n",
      "Epoch 17/5000\n",
      "2036/2036 [==============================] - 1s 257us/step - loss: 0.4445\n",
      "Epoch 18/5000\n",
      "2036/2036 [==============================] - 0s 234us/step - loss: 0.4445\n",
      "Epoch 19/5000\n",
      "2036/2036 [==============================] - 0s 234us/step - loss: 0.4445\n",
      "Epoch 20/5000\n",
      "2036/2036 [==============================] - 0s 241us/step - loss: 0.4445\n",
      "Epoch 21/5000\n",
      "2036/2036 [==============================] - 1s 322us/step - loss: 0.4445\n",
      "Epoch 22/5000\n",
      "2036/2036 [==============================] - 1s 288us/step - loss: 0.4445\n",
      "Epoch 23/5000\n",
      "2036/2036 [==============================] - 1s 264us/step - loss: 0.4445\n",
      "Epoch 24/5000\n",
      "2036/2036 [==============================] - 1s 253us/step - loss: 0.4445\n",
      "Epoch 25/5000\n",
      "2036/2036 [==============================] - 1s 255us/step - loss: 0.4445\n",
      "Epoch 26/5000\n",
      "2036/2036 [==============================] - 1s 282us/step - loss: 0.4445\n",
      "Epoch 27/5000\n",
      "2036/2036 [==============================] - 1s 301us/step - loss: 0.4445\n",
      "Epoch 28/5000\n",
      "2036/2036 [==============================] - 1s 298us/step - loss: 0.4445\n",
      "Epoch 29/5000\n",
      "2036/2036 [==============================] - 1s 297us/step - loss: 0.4445\n",
      "Epoch 30/5000\n",
      "2036/2036 [==============================] - 1s 274us/step - loss: 0.4445\n",
      "Epoch 31/5000\n",
      "2036/2036 [==============================] - 1s 260us/step - loss: 0.4445\n",
      "Epoch 32/5000\n",
      "2036/2036 [==============================] - 1s 251us/step - loss: 0.4445\n",
      "Epoch 33/5000\n",
      "2036/2036 [==============================] - 0s 245us/step - loss: 0.4445\n",
      "Epoch 34/5000\n",
      "2036/2036 [==============================] - 1s 263us/step - loss: 0.4445\n",
      "Epoch 35/5000\n",
      "2036/2036 [==============================] - 0s 227us/step - loss: 0.4445\n",
      "Epoch 36/5000\n",
      "2036/2036 [==============================] - 1s 255us/step - loss: 0.4445\n",
      "Epoch 37/5000\n",
      "2036/2036 [==============================] - 1s 253us/step - loss: 0.4445\n",
      "Epoch 38/5000\n",
      "2036/2036 [==============================] - 1s 258us/step - loss: 0.4445\n",
      "Epoch 39/5000\n",
      "2036/2036 [==============================] - 1s 248us/step - loss: 0.4445\n",
      "Epoch 40/5000\n",
      "2036/2036 [==============================] - 1s 255us/step - loss: 0.4445\n",
      "Epoch 41/5000\n",
      "2036/2036 [==============================] - 0s 235us/step - loss: 0.4445\n",
      "Epoch 42/5000\n",
      "2036/2036 [==============================] - 0s 243us/step - loss: 0.4445\n",
      "Epoch 43/5000\n",
      "2036/2036 [==============================] - 1s 256us/step - loss: 0.4445\n",
      "Epoch 44/5000\n",
      "2036/2036 [==============================] - 0s 223us/step - loss: 0.4445\n",
      "Epoch 45/5000\n",
      "2036/2036 [==============================] - 0s 225us/step - loss: 0.4445\n",
      "Epoch 46/5000\n",
      "2036/2036 [==============================] - 1s 246us/step - loss: 0.4445\n",
      "Epoch 47/5000\n",
      "2036/2036 [==============================] - 1s 300us/step - loss: 0.4445\n",
      "Epoch 48/5000\n",
      "2036/2036 [==============================] - 1s 325us/step - loss: 0.4445\n",
      "Epoch 49/5000\n",
      "2036/2036 [==============================] - 0s 223us/step - loss: 0.4445\n",
      "Epoch 50/5000\n",
      "2036/2036 [==============================] - 1s 288us/step - loss: 0.4445\n",
      "Epoch 51/5000\n",
      "2036/2036 [==============================] - 1s 248us/step - loss: 0.4445\n",
      "Epoch 52/5000\n",
      "2036/2036 [==============================] - 1s 363us/step - loss: 0.4445\n",
      "Epoch 53/5000\n",
      "2036/2036 [==============================] - 1s 287us/step - loss: 0.4445\n",
      "Epoch 54/5000\n",
      "2036/2036 [==============================] - 1s 303us/step - loss: 0.4445\n",
      "Epoch 55/5000\n",
      "2036/2036 [==============================] - 1s 342us/step - loss: 0.4445\n",
      "Epoch 56/5000\n",
      "2036/2036 [==============================] - 1s 353us/step - loss: 0.4445\n",
      "Epoch 57/5000\n",
      "2036/2036 [==============================] - 1s 364us/step - loss: 0.4445\n",
      "Epoch 58/5000\n",
      "2036/2036 [==============================] - 1s 261us/step - loss: 0.4445\n",
      "Epoch 59/5000\n",
      "2036/2036 [==============================] - 1s 310us/step - loss: 0.4445\n",
      "Epoch 60/5000\n",
      "2036/2036 [==============================] - 1s 362us/step - loss: 0.4445\n",
      "Epoch 61/5000\n",
      "2036/2036 [==============================] - 1s 343us/step - loss: 0.4445\n",
      "Epoch 62/5000\n",
      "2036/2036 [==============================] - 1s 267us/step - loss: 0.4445\n",
      "Epoch 63/5000\n",
      "2036/2036 [==============================] - 1s 264us/step - loss: 0.4445\n",
      "Epoch 64/5000\n",
      "2036/2036 [==============================] - 1s 265us/step - loss: 0.4445\n",
      "Epoch 65/5000\n",
      "2036/2036 [==============================] - 1s 255us/step - loss: 0.4445\n",
      "Epoch 66/5000\n",
      "2036/2036 [==============================] - 1s 354us/step - loss: 0.4445\n",
      "Epoch 67/5000\n",
      "2036/2036 [==============================] - 1s 280us/step - loss: 0.4445\n",
      "Epoch 68/5000\n",
      "2036/2036 [==============================] - 0s 229us/step - loss: 0.4445\n",
      "Epoch 69/5000\n",
      "2036/2036 [==============================] - 0s 224us/step - loss: 0.4445\n",
      "Epoch 70/5000\n",
      "2036/2036 [==============================] - 0s 196us/step - loss: 0.4445\n",
      "Epoch 71/5000\n",
      "2036/2036 [==============================] - 0s 236us/step - loss: 0.4445\n",
      "Epoch 72/5000\n",
      "2036/2036 [==============================] - 0s 243us/step - loss: 0.4445\n",
      "Epoch 73/5000\n",
      "2036/2036 [==============================] - 1s 251us/step - loss: 0.4445\n",
      "Epoch 74/5000\n",
      "2036/2036 [==============================] - 1s 247us/step - loss: 0.4445\n",
      "Epoch 75/5000\n",
      "2036/2036 [==============================] - 1s 264us/step - loss: 0.4445\n",
      "Epoch 76/5000\n",
      "2036/2036 [==============================] - 1s 334us/step - loss: 0.4445 0s - lo\n",
      "Epoch 77/5000\n",
      "2036/2036 [==============================] - 1s 326us/step - loss: 0.4445\n",
      "Epoch 78/5000\n",
      "2036/2036 [==============================] - 1s 262us/step - loss: 0.4445\n",
      "Epoch 79/5000\n",
      "2036/2036 [==============================] - 1s 304us/step - loss: 0.4445\n",
      "Epoch 80/5000\n",
      "2036/2036 [==============================] - 1s 246us/step - loss: 0.4445\n",
      "Epoch 81/5000\n",
      "2036/2036 [==============================] - 1s 274us/step - loss: 0.4445\n",
      "Epoch 82/5000\n",
      "2036/2036 [==============================] - 1s 267us/step - loss: 0.4445\n",
      "Epoch 83/5000\n",
      "2036/2036 [==============================] - 0s 231us/step - loss: 0.4445\n",
      "Epoch 84/5000\n",
      "2036/2036 [==============================] - 0s 232us/step - loss: 0.4445\n",
      "Epoch 85/5000\n",
      "2036/2036 [==============================] - 1s 252us/step - loss: 0.4445\n",
      "Epoch 86/5000\n",
      "2036/2036 [==============================] - 0s 234us/step - loss: 0.4445\n",
      "Epoch 87/5000\n",
      "2036/2036 [==============================] - 0s 230us/step - loss: 0.4445\n",
      "Epoch 88/5000\n",
      "2036/2036 [==============================] - 1s 248us/step - loss: 0.4445\n",
      "Epoch 89/5000\n",
      "2036/2036 [==============================] - 1s 248us/step - loss: 0.4445\n",
      "Epoch 90/5000\n",
      "2036/2036 [==============================] - 1s 300us/step - loss: 0.4445\n",
      "Epoch 91/5000\n",
      "2036/2036 [==============================] - 1s 341us/step - loss: 0.4445\n",
      "Epoch 92/5000\n",
      "2036/2036 [==============================] - 1s 325us/step - loss: 0.4445\n",
      "Epoch 93/5000\n",
      "2036/2036 [==============================] - 1s 289us/step - loss: 0.4445\n",
      "Epoch 94/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/2036 [===============>..............] - ETA: 0s - loss: 0.6637"
     ]
    }
   ],
   "source": [
    "history=model1.fit(X_train,y_train, epochs=5000, shuffle=False,batch_size=64, verbose=1)\n",
    "model1.save('./models/attempt2.h5')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "#plt.plot(history.history['rmse'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs= pywt.wavedec2(price_test, 'haar',  mode='symmetric',level=2)\n",
    "coeffs[-1] = tuple([np.zeros_like(v) for v in coeffs[-1]])\n",
    "c=pywt.waverec2(coeffs,'haar')\n",
    "coeffs1=pywt.wavedec2(c,'haar', mode='symmetric', level=2)\n",
    "coeffs1[-1] = tuple([np.zeros_like(v) for v in coeffs1[-1]])\n",
    "d=pywt.waverec2(coeffs1, 'haar')\n",
    "exp_X_test[:,0] = d[:-1,0]\n",
    "exp_X_test[:,1] = d[:-1,1]\n",
    "exp_X_test[:,2] = d[:1,2]\n",
    "exp_X_test[:,3] = d[:-1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.229642</td>\n",
       "      <td>0.229642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212028</td>\n",
       "      <td>0.175164</td>\n",
       "      <td>0.262385</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>0.728412</td>\n",
       "      <td>0.826158</td>\n",
       "      <td>0.203232</td>\n",
       "      <td>0.215146</td>\n",
       "      <td>0.228363</td>\n",
       "      <td>0.970464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.229642</td>\n",
       "      <td>0.229642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213670</td>\n",
       "      <td>0.178681</td>\n",
       "      <td>0.261858</td>\n",
       "      <td>0.012796</td>\n",
       "      <td>0.728362</td>\n",
       "      <td>0.754516</td>\n",
       "      <td>0.206201</td>\n",
       "      <td>0.217720</td>\n",
       "      <td>0.234730</td>\n",
       "      <td>0.866327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.216077</td>\n",
       "      <td>0.216077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214293</td>\n",
       "      <td>0.180176</td>\n",
       "      <td>0.261483</td>\n",
       "      <td>0.020926</td>\n",
       "      <td>0.723947</td>\n",
       "      <td>0.579582</td>\n",
       "      <td>0.207917</td>\n",
       "      <td>0.219924</td>\n",
       "      <td>0.236289</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.216077</td>\n",
       "      <td>0.216077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215018</td>\n",
       "      <td>0.181211</td>\n",
       "      <td>0.261820</td>\n",
       "      <td>0.015203</td>\n",
       "      <td>0.716659</td>\n",
       "      <td>0.582195</td>\n",
       "      <td>0.208689</td>\n",
       "      <td>0.221037</td>\n",
       "      <td>0.234947</td>\n",
       "      <td>0.653061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.220899</td>\n",
       "      <td>0.220899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216376</td>\n",
       "      <td>0.183315</td>\n",
       "      <td>0.262271</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>0.713512</td>\n",
       "      <td>0.614151</td>\n",
       "      <td>0.210449</td>\n",
       "      <td>0.222892</td>\n",
       "      <td>0.234122</td>\n",
       "      <td>0.801020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1    2         3    4         5         6         7   \\\n",
       "0  0.229642  0.229642  0.0  0.246467  0.0  0.212028  0.175164  0.262385   \n",
       "1  0.229642  0.229642  0.0  0.246467  0.0  0.213670  0.178681  0.261858   \n",
       "2  0.216077  0.216077  0.0  0.234338  0.0  0.214293  0.180176  0.261483   \n",
       "3  0.216077  0.216077  0.0  0.234338  0.0  0.215018  0.181211  0.261820   \n",
       "4  0.220899  0.220899  0.0  0.238047  0.0  0.216376  0.183315  0.262271   \n",
       "\n",
       "         8         9         10        11        12        13        14  \n",
       "0  0.016663  0.728412  0.826158  0.203232  0.215146  0.228363  0.970464  \n",
       "1  0.012796  0.728362  0.754516  0.206201  0.217720  0.234730  0.866327  \n",
       "2  0.020926  0.723947  0.579582  0.207917  0.219924  0.236289  0.750000  \n",
       "3  0.015203  0.716659  0.582195  0.208689  0.221037  0.234947  0.653061  \n",
       "4  0.009286  0.713512  0.614151  0.210449  0.222892  0.234122  0.801020  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_X_test=scaler.transform(exp_X_test)\n",
    "#exp_X_test=scaler.fit_transform(exp_X_test)\n",
    "scaled_df1=pd.DataFrame(exp_X_test)\n",
    "scaled_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = exp_X_test[:,1]\n",
    "exp_X_test = np.delete(exp_X_test, 1, axis=1)\n",
    "X_test=exp_X_test.reshape((exp_X_test.shape[0],1,exp_X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model1.predict(X_test)\n",
    "actual= pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pred, color='green',linewidth=0.4)\n",
    "plt.plot(actual, color='red', linewidth=0.4)\n",
    "plt.savefig('./sae_prediction.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse, rmse, mae:(0.001287474686653091, 0.03588139750139466, 0.027988156828800452)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "mse = mean_squared_error(actual, pred)\n",
    "rmse = math.sqrt(mse)\n",
    "mae = mean_absolute_error(actual, pred)\n",
    "#mape = mean_absolute_percentage_error(actual, pred)\n",
    "print(\"mse, rmse, mae:\" + str((mse,rmse,mae)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
